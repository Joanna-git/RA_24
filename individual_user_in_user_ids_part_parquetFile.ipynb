{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths and constants\n",
    "master_file = \"individual_user_in_user_ids_file.txt\"\n",
    "checkpoint_file = \"completed_individual_user_parquet_files.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File names have been written to individual_user_in_user_ids_file.txt\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder containing the .parquet files\n",
    "folder_path = \"individual_user_extracted\"\n",
    "\n",
    "# List all .parquet files in the folder\n",
    "parquet_files = [f for f in os.listdir(folder_path) if f.endswith('.parquet')]\n",
    "\n",
    "# Write file names to the text file\n",
    "with open(master_file, 'w') as file:\n",
    "    for parquet_file in parquet_files:\n",
    "        file.write(parquet_file + '\\n')\n",
    "\n",
    "print(f\"File names have been written to {master_file}\")        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the list of .txt files\n",
    "with open(master_file, 'r') as f:\n",
    "    txt_files = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Load the list of already processed files\n",
    "if os.path.exists(checkpoint_file):\n",
    "    with open(checkpoint_file, 'r') as f:\n",
    "        completed_files = set(line.strip() for line in f.readlines())\n",
    "else:\n",
    "    completed_files = set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found parquet files: ['individual_user_in_user_ids_part_001.parquet', 'individual_user_in_user_ids_part_002.parquet', 'individual_user_in_user_ids_part_003.parquet']\n",
      "Files to process: ['individual_user_in_user_ids_part_001.parquet', 'individual_user_in_user_ids_part_002.parquet', 'individual_user_in_user_ids_part_003.parquet']\n"
     ]
    }
   ],
   "source": [
    "# Filter files that still need to be processed\n",
    "print(f\"Found parquet files: {parquet_files}\")\n",
    "files_to_process = [file for file in txt_files if file not in completed_files]\n",
    "print(f\"Files to process: {files_to_process}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_folder='us_individual_user_extracted'\n",
    "os.makedirs(result_folder, exist_ok=True)  # Create the folder if it doesn't exist\n",
    "# File to store uncategorized users' ids\n",
    "uncategorized_file = \"uncategorized_individual_user.txt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process: individual_user_in_user_ids_part_001.parquet\n",
      "Results saved to us_individual_user_extracted\\individual_user_in_user_ids_part_001.parquet\n",
      "Checkpoint updated for individual_user_in_user_ids_part_001.parquet. Moving to the next file...\n",
      "\n",
      "Starting to process: individual_user_in_user_ids_part_002.parquet\n",
      "Results saved to us_individual_user_extracted\\individual_user_in_user_ids_part_002.parquet\n",
      "Checkpoint updated for individual_user_in_user_ids_part_002.parquet. Moving to the next file...\n",
      "\n",
      "Starting to process: individual_user_in_user_ids_part_003.parquet\n",
      "Results saved to us_individual_user_extracted\\individual_user_in_user_ids_part_003.parquet\n",
      "Checkpoint updated for individual_user_in_user_ids_part_003.parquet. Moving to the next file...\n",
      "\n",
      "All files processed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each file to process\n",
    "for txt_file in files_to_process:\n",
    "    file_path = os.path.join(folder_path, txt_file)\n",
    "\n",
    "    try:\n",
    "        print(f\"Starting to process: {txt_file}\")\n",
    "        # Load parquet file into DataFrame\n",
    "        df = pd.read_parquet(file_path)\n",
    "\n",
    "        # Add is_in_us column\n",
    "        df['is_in_us'] = df['user_country'].apply(\n",
    "            lambda x: 1 if x == \"United States\" else (0 if isinstance(x, str) else None)\n",
    "        )\n",
    "\n",
    "        # Handle uncategorized rows\n",
    "        uncategorized_users = df[df['is_in_us'].isnull()]\n",
    "\n",
    "\n",
    "        if not uncategorized_users.empty:\n",
    "            with open(uncategorized_file, 'a') as uncategorized:\n",
    "                for user_id in uncategorized_users['user_id']:\n",
    "                    uncategorized.write(f\"{int(user_id)}\\n\")\n",
    "            # Drop uncategorized rows\n",
    "            df = df.dropna(subset=['is_in_us'])\n",
    "\n",
    "        # Save the result as a .parquet file\n",
    "        output_file = os.path.join(result_folder, txt_file)\n",
    "        df.to_parquet(output_file, index=False)\n",
    "        print(f\"Results saved to {output_file}\")\n",
    "        \n",
    "        # Update the checkpoint file after successful processing\n",
    "        with open(checkpoint_file, 'a') as f:\n",
    "            f.write(txt_file + '\\n')\n",
    "        print(f\"Checkpoint updated for {txt_file}. Moving to the next file...\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {txt_file}: {e}\")\n",
    "        break  # Stop the process if an error occurs\n",
    "print(\"All files processed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
